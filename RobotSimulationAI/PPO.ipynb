{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import websockets, asyncio\n",
    "import threading\n",
    "\n",
    "class WaitableQueue(asyncio.Queue):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.event = threading.Event()\n",
    "\n",
    "    def put(self, item):\n",
    "        super().put_nowait(item)\n",
    "        self.event.set()\n",
    "\n",
    "    def get(self,timeout=1000000000):\n",
    "        if self.event.wait(timeout):\n",
    "            res = super().get_nowait()\n",
    "            if super().empty():\n",
    "                self.event.clear()\n",
    "            return res\n",
    "        else:\n",
    "            raise TimeoutError(\"Environement is not responding.\")\n",
    "\n",
    "    def waitNotEmpty(self,timeout=1000000000):\n",
    "        if self.event.wait(timeout):    \n",
    "            return\n",
    "        else:\n",
    "            raise TimeoutError(\"Environement is not responding.\")\n",
    "\n",
    "# the server\n",
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.inQueue = WaitableQueue()\n",
    "        self.outQueue = WaitableQueue()\n",
    "        self.debug = True\n",
    "        self.ws = None\n",
    "\n",
    "    def start(self):\n",
    "        threading.Thread(target=self.message_sender_loop).start()\n",
    "        asyncio.run(self.main())\n",
    "\n",
    "    async def main(self):\n",
    "        try:\n",
    "            async with websockets.serve(self.echo, \"localhost\", 8766):\n",
    "                await asyncio.Future()  # run forever\n",
    "        except websockets.exceptions.ConnectionClosedError as e: print(e)\n",
    "\n",
    "    async def echo(self,websocket):\n",
    "        self.ws = websocket\n",
    "        print('connect')\n",
    "        #asyncio.create_task(self.message_sender_loop())\n",
    "        async for message in websocket:\n",
    "            try:\n",
    "                self.recv(json.loads(message))\n",
    "            except json.decoder.JSONDecodeError:\n",
    "                self.recv(message)\n",
    "\n",
    "    def recv(self,message):\n",
    "        self.inQueue.put(message)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"recv: \",message)\n",
    "    \n",
    "    def send(self,command:str, content):\n",
    "        self.outQueue.put({'command':command,'content':content})\n",
    "\n",
    "    def message_sender_loop(self):\n",
    "        while True:\n",
    "            try:\n",
    "                message = self.outQueue.get(None)\n",
    "                asyncio.run(self.ws.send(json.dumps(message, indent=4)))\n",
    "            except websockets.exceptions.ConnectionClosedError:\n",
    "                print(\"Connection closed\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "    def update(self,handler):\n",
    "        while not self.inQueue.empty:\n",
    "            message = self.inQueue.get()\n",
    "            getattr(handler, message[\"command\"])(message[\"content\"])\n",
    "\n",
    "                \n",
    "# start the server in a separate thread to avoid blocking\n",
    "import threading\n",
    "server = Server()\n",
    "t=threading.Thread(target=server.start)\n",
    "t.start()\n",
    "\n",
    "# the interface to the server\n",
    "class WSManager:\n",
    "    def __init__(self,server:Server):\n",
    "        self.debug = False\n",
    "        self.server = server\n",
    "\n",
    "#server.send(\"action\",{\"voltage\":[1,0,0,0,100,200,100,100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def flatten(list_of_lists):\n",
    "    if len(list_of_lists) == 0:\n",
    "        return list(list_of_lists)\n",
    "    if hasattr(list_of_lists[0], '__iter__'):\n",
    "        return flatten(list_of_lists[0]) + flatten(list_of_lists[1:])\n",
    "    return list(list_of_lists[:1]) + flatten(list_of_lists[1:])\n",
    "def decomposeCosSin(angle):\n",
    "    return [np.cos(angle), np.sin(angle)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'send'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import nn\n",
    "import gym\n",
    "import numpy as np\n",
    "class Environment(gym.Env):\n",
    "    def __init__(self,ws_server : Server,device = 'cpu'):\n",
    "        self.ws = ws_server\n",
    "        self.t = 0\n",
    "        self.t_episode = 0\n",
    "        self.device = device\n",
    "        self.prevState = None\n",
    "        self.prevAction = None\n",
    "        self.targetPos = None\n",
    "        self.noiseIntensity = 0.5\n",
    "        self.hasRecievedState = False\n",
    "        self.pos = np.array([0.,0.])\n",
    "        self.ws.send(\"pos\",{'x':0,'y':0, 'z':0})\n",
    "        self.training = True\n",
    "        self.timeSetp = 0.1\n",
    "        self.timePenalty = 0\n",
    "\n",
    "        # Implement gym.Env\n",
    "        self.observation_space = gym.spaces.Box(-np.inf,np.inf,shape=(19,),dtype=float)\n",
    "        self.action_space = gym.spaces.Box(-1,1,shape=(8,),dtype=float)\n",
    "\n",
    "    def processFeature(self,state:dict):\n",
    "        feature = []\n",
    "        feature.append(state['baseLinkPos']['x']-self.targetPos[0].item())\n",
    "        feature.append(state['baseLinkPos']['y']-self.targetPos[1].item())\n",
    "        feature.append(decomposeCosSin(state['baseLinkOrientation']))\n",
    "        feature.append(state['baseLinkVelocity']['x'])\n",
    "        feature.append(state['baseLinkVelocity']['y'])\n",
    "        feature.append(state['baseLinkAngularVelocity'])\n",
    "        feature.append(decomposeCosSin(state['wheelBaseOrientation']))\n",
    "        feature.append(state['wheelSpeed'])\n",
    "        feature = flatten(feature)\n",
    "        return feature\n",
    "\n",
    "    def getObservation(self):\n",
    "        return self.processFeature(self.state)\n",
    "\n",
    "    def calculateReward(self,pos,targetPos):\n",
    "        return -np.linalg.norm(pos-targetPos,2)\n",
    "\n",
    "    def terminateCondition(self,pos,targetPos):\n",
    "        if not self.training:\n",
    "            return False, False\n",
    "        d = np.linalg.norm(pos-targetPos,2)\n",
    "        return d<0.5 or d>15 or self.t_episode>100, d<0.5\n",
    "\n",
    "    def getPos(self,state):\n",
    "        return np.array([state['baseLinkPos']['x'],state['baseLinkPos']['y']],dtype=float)\n",
    "\n",
    "    def readMessages(self):\n",
    "        while not self.ws.inQueue.empty():\n",
    "            message = self.ws.inQueue.get()\n",
    "            command = message[\"command\"]\n",
    "            content = message[\"content\"]\n",
    "            if command == \"state\":\n",
    "                self.hasRecievedState = True\n",
    "                self.state = message[\"content\"]\n",
    "            if command == \"target\":\n",
    "                self.targetPos = np.array([content[\"x\"],content[\"z\"]])\n",
    "\n",
    "    def wheelOrientationMotorMapping(self,x):\n",
    "        gamma = 10\n",
    "        return x**10\n",
    "\n",
    "\n",
    "    # Implement gym.Env\n",
    "    \n",
    "    def reset(self):\n",
    "        self.targetPos = self.pos + np.random.standard_normal((2,))*4\n",
    "        self.t_episode = 0\n",
    "        self.prevState = None\n",
    "        self.ws.send(\"target\",{\"pos\":{'x':self.targetPos[0],'y':0, 'z':self.targetPos[1]}})\n",
    "        #self.ws.send(\"pos\",{'x':0,'y':0, 'z':0})\n",
    "        self.ws.send(\"require state\",None)\n",
    "\n",
    "        # return the initial observation\n",
    "        self.hasRecievedState = False\n",
    "        while not self.hasRecievedState:\n",
    "            self.ws.inQueue.waitNotEmpty()\n",
    "            self.readMessages()\n",
    "\n",
    "        return self.getObservation()\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.t_episode +=1\n",
    "        # Send an action then wait for the env to run one step\n",
    "        action[0:4] = self.wheelOrientationMotorMapping(action[0:4])\n",
    "        action[0:4]*=1000\n",
    "        action[4:8]*=2000\n",
    "        self.ws.send(\"action\", {\"voltage\":action.tolist()})\n",
    "        #self.ws.send(\"action\", {\"voltage\":[1000,1000,1000,1000,0,0,0,0]})\n",
    "\n",
    "        prevPos = self.getPos(self.state)\n",
    "\n",
    "        # Get state and calculate stuffs in the step\n",
    "        \n",
    "        self.hasRecievedState = False\n",
    "        while not self.hasRecievedState:\n",
    "            self.ws.inQueue.waitNotEmpty()\n",
    "            self.readMessages()\n",
    "\n",
    "        observation = self.getObservation()\n",
    "        self.pos = self.getPos(self.state)\n",
    "\n",
    "        distReward = self.calculateReward(self.pos,self.targetPos) - self.calculateReward(prevPos,self.targetPos)\n",
    "        timePanelty = self.timePenalty*self.timeSetp\n",
    "        reward = distReward + timePanelty\n",
    "\n",
    "        done, goal = self.terminateCondition(self.pos,self.targetPos)\n",
    "\n",
    "        if goal:\n",
    "            reward += 10\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, done, info\n",
    "env = Environment(server,'cuda')\n",
    "server.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import datetime\n",
    "size = 256\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1,device = \"cuda\",gamma=0.99,policy_kwargs={'net_arch':[dict(pi=[size, size], vf=[size, size])]},tensorboard_log=\"runs/wheel=fixed,gamma=0.99,timePanelty=0,goalReward=10,size=256;\"+datetime.datetime.now().strftime(\"%m_%d_%Y/%H_%M_%S\"))\n",
    "#model = PPO.load(\"1002k_06_27_2022_00_38_11.zip\",env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to runs/wheel=fixed,gamma=0.99,timePanelty=0,goalReward=10,size=256;06_29_2022/01_05_32/PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.2     |\n",
      "|    ep_rew_mean     | 13.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 51       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.9        |\n",
      "|    ep_rew_mean          | 13.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032597966 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.409       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 0.914       |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.1        |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038424697 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.5        |\n",
      "|    ep_rew_mean          | 12.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032092474 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.744       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.2        |\n",
      "|    ep_rew_mean          | 13.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028514452 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.753       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.6        |\n",
      "|    ep_rew_mean          | 13.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049254116 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.6       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 0.921       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.3        |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028963728 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.497       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 36.7       |\n",
      "|    ep_rew_mean          | 14.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 47         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 347        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03315135 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.5      |\n",
      "|    explained_variance   | 0.377      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.241      |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 0.905      |\n",
      "|    value_loss           | 1.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.5        |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029844357 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 0.396       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.4        |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029566174 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.396       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.904       |\n",
      "|    value_loss           | 0.863       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.8        |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032148406 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 0.898       |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.6        |\n",
      "|    ep_rew_mean          | 14.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028929424 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.421       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.6        |\n",
      "|    ep_rew_mean          | 14.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 576         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031160973 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0877      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.891       |\n",
      "|    value_loss           | 0.408       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 33        |\n",
      "|    ep_rew_mean          | 14.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 46        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 622       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0346276 |\n",
      "|    clip_fraction        | 0.35      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -10.4     |\n",
      "|    explained_variance   | 0.559     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0824    |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -0.0171   |\n",
      "|    std                  | 0.891     |\n",
      "|    value_loss           | 0.663     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039858077 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.4       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0789      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 0.663       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.7        |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028464604 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 38.1       |\n",
      "|    ep_rew_mean          | 14.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04030861 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.3      |\n",
      "|    explained_variance   | 0.49       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.184      |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    std                  | 0.873      |\n",
      "|    value_loss           | 0.534      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.1        |\n",
      "|    ep_rew_mean          | 15          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039671674 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0973      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.5        |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 843         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031094424 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.7        |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034716096 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.062       |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    std                  | 0.86        |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 33.7       |\n",
      "|    ep_rew_mean          | 14.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 932        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03385497 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.706      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00332    |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.0259    |\n",
      "|    std                  | 0.863      |\n",
      "|    value_loss           | 0.283      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 14.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 978         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039374493 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0957      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00971    |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.371       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 14          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1026        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040748272 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0732      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 0.86        |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29.4       |\n",
      "|    ep_rew_mean          | 14.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 45         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 1074       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03730061 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.572      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.865      |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 0.859      |\n",
      "|    value_loss           | 0.871      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.6        |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1120        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034943692 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00778     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "Logging to runs/wheel=fixed,gamma=0.99,timePanelty=0,goalReward=10,size=256;06_29_2022/01_05_32/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.2     |\n",
      "|    ep_rew_mean     | 14.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 43       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.3        |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033575777 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 0.779       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.3        |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038846847 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.1       |\n",
      "|    ep_rew_mean          | 14.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 187        |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03815855 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00332    |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    std                  | 0.86       |\n",
      "|    value_loss           | 0.177      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.6       |\n",
      "|    ep_rew_mean          | 14.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 233        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03648504 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.85       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0507     |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    std                  | 0.859      |\n",
      "|    value_loss           | 0.166      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 27.1       |\n",
      "|    ep_rew_mean          | 14.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 279        |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03178347 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0629     |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0212    |\n",
      "|    std                  | 0.857      |\n",
      "|    value_loss           | 0.48       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 26.4       |\n",
      "|    ep_rew_mean          | 14.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04262886 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.1      |\n",
      "|    explained_variance   | 0.721      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0166     |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0217    |\n",
      "|    std                  | 0.854      |\n",
      "|    value_loss           | 0.217      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043153636 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10         |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.3        |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041065354 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.98       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.04        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    std                  | 0.845       |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.6        |\n",
      "|    ep_rew_mean          | 14.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045853637 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.93       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 0.456       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 25.6       |\n",
      "|    ep_rew_mean          | 14.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 512        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03430245 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.9       |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0103     |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    std                  | 0.838      |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030212872 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.88       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.514       |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.835       |\n",
      "|    value_loss           | 0.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.9        |\n",
      "|    ep_rew_mean          | 13.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041564323 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.88       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00635    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.5        |\n",
      "|    ep_rew_mean          | 14.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037637316 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.88       |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 0.886       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 24.9       |\n",
      "|    ep_rew_mean          | 14.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 700        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04232485 |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.88      |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0518     |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.009     |\n",
      "|    std                  | 0.837      |\n",
      "|    value_loss           | 0.203      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connection handler failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 945, in transfer_data\n",
      "    message = await self.read_message()\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 1015, in read_message\n",
      "    frame = await self.read_data_frame(max_size=self.max_size)\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 1090, in read_data_frame\n",
      "    frame = await self.read_frame(max_size)\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 1145, in read_frame\n",
      "    frame = await Frame.read(\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/framing.py\", line 70, in read\n",
      "    data = await reader(2)\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/asyncio/streams.py\", line 738, in readexactly\n",
      "    raise exceptions.IncompleteReadError(incomplete, n)\n",
      "asyncio.exceptions.IncompleteReadError: 0 bytes read on a total of 2 expected bytes\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/server.py\", line 232, in handler\n",
      "    await self.ws_handler(self)\n",
      "  File \"/tmp/ipykernel_2233464/3257988145.py\", line 51, in echo\n",
      "    async for message in websocket:\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 482, in __aiter__\n",
      "    yield await self.recv()\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 553, in recv\n",
      "    await self.ensure_open()\n",
      "  File \"/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/websockets/legacy/protocol.py\", line 921, in ensure_open\n",
      "    raise self.connection_closed_exc()\n",
      "websockets.exceptions.ConnectionClosedError: no close frame received or sent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 22.1       |\n",
      "|    ep_rew_mean          | 5.06       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 757        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05015209 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.86      |\n",
      "|    explained_variance   | 0.807      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0123     |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    std                  | 0.835      |\n",
      "|    value_loss           | 0.508      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23          |\n",
      "|    ep_rew_mean          | 14.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038339593 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.82       |\n",
      "|    explained_variance   | 0.00242     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.829       |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20         |\n",
      "|    ep_rew_mean          | 14.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 845        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04198696 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.79      |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00252   |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    std                  | 0.828      |\n",
      "|    value_loss           | 0.363      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.5        |\n",
      "|    ep_rew_mean          | 14.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 887         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036808718 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.77       |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.6       |\n",
      "|    ep_rew_mean          | 14.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 43         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 932        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04607871 |\n",
      "|    clip_fraction        | 0.409      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.74      |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0102     |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.0251    |\n",
      "|    std                  | 0.823      |\n",
      "|    value_loss           | 0.241      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.5        |\n",
      "|    ep_rew_mean          | 14.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 978         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045424942 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.69       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0138      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.5        |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1022        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052434646 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.66       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0851      |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    std                  | 0.815       |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.3        |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1065        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038898155 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.63       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00135     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 0.0983      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 21.6       |\n",
      "|    ep_rew_mean          | 14.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 1109       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04128295 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.61      |\n",
      "|    explained_variance   | 0.916      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0386    |\n",
      "|    n_updates            | 810        |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    std                  | 0.81       |\n",
      "|    value_loss           | 0.0774     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.3        |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1153        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050045427 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.58       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0291     |\n",
      "|    std                  | 0.806       |\n",
      "|    value_loss           | 0.09        |\n",
      "-----------------------------------------\n",
      "Logging to runs/wheel=fixed,gamma=0.99,timePanelty=0,goalReward=10,size=256;06_29_2022/01_05_32/PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | 14.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 48       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2233464/4063253035.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{67+i*50}k_06_29_2022_01_05_32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    302\u001b[0m     ) -> \"PPO\":\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         return super(PPO, self).learn(\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2233464/452022791.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasRecievedState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasRecievedState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minQueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitNotEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadMessages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2233464/3257988145.py\u001b[0m in \u001b[0;36mwaitNotEmpty\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwaitNotEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.training = True\n",
    "for i in range(20):\n",
    "    model.save(f\"{67+i*50}k_06_29_2022_01_05_32\")\n",
    "    model.learn(total_timesteps=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eri24816/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2233464/2531287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_eval_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(model, env, n_eval_episodes, deterministic, render, callback, reward_threshold, return_episode_rewards, warn)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepisode_counts\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepisode_count_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepisode_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mcurrent_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mcurrent_lengths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             )\n",
      "\u001b[0;32m/tmp/ipykernel_2233464/452022791.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasRecievedState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasRecievedState\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minQueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitNotEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadMessages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2233464/3257988145.py\u001b[0m in \u001b[0;36mwaitNotEmpty\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwaitNotEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/expansion/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import stable_baselines3\n",
    "env.training = False \n",
    "stable_baselines3.common.evaluation.evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"67k_06_29_2022_01_05_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(1, 2) (<class 'tuple'>) invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39112\\2527115399.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\a931e\\Anaconda3\\envs\\nn\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\a931e\\Anaconda3\\envs\\nn\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%r (%s) invalid\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_dot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: (1, 2) (<class 'tuple'>) invalid"
     ]
    }
   ],
   "source": [
    "env.step((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model1 = PPO(\"MlpPolicy\", env, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03819583, -0.18100157,  0.01109779,  0.3364094 ], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _states = model1.predict(obs, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.309618491520645"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.5)/np.log(0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6931471805599453"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('expansion')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f59ea5be274cd00b445a91a0a642fdb2ab107e11b66ee0fd9e74522bc545109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
