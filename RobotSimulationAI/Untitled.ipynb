{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import websockets, asyncio\n",
    "import threading\n",
    "\n",
    "class WaitableQueue(asyncio.Queue):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.event = threading.Event()\n",
    "\n",
    "    def put(self, item):\n",
    "        super().put_nowait(item)\n",
    "        self.event.set()\n",
    "\n",
    "    def get(self,timeout=3):\n",
    "        if self.event.wait(timeout):\n",
    "            res = super().get_nowait()\n",
    "            if super().empty():\n",
    "                self.event.clear()\n",
    "            return res\n",
    "        else:\n",
    "            raise TimeoutError(\"Environement is not responding.\")\n",
    "\n",
    "# the server\n",
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.inQueue = WaitableQueue()\n",
    "        self.outQueue = WaitableQueue()\n",
    "        self.debug = True\n",
    "        self.ws = None\n",
    "\n",
    "    def start(self):\n",
    "        threading.Thread(target=self.message_sender_loop).start()\n",
    "        asyncio.run(self.main())\n",
    "\n",
    "    async def main(self):\n",
    "        try:\n",
    "            async with websockets.serve(self.echo, \"localhost\", 8765):\n",
    "                await asyncio.Future()  # run forever\n",
    "        except websockets.exceptions.ConnectionClosedError as e: print(e)\n",
    "\n",
    "    async def echo(self,websocket):\n",
    "        self.ws = websocket\n",
    "        print('connect')\n",
    "        #asyncio.create_task(self.message_sender_loop())\n",
    "        async for message in websocket:\n",
    "            try:\n",
    "                self.recv(json.loads(message))\n",
    "            except json.decoder.JSONDecodeError:\n",
    "                self.recv(message)\n",
    "\n",
    "    def recv(self,message):\n",
    "        self.inQueue.put(message)\n",
    "        if self.debug:\n",
    "            print(\"recv: \",message)\n",
    "    \n",
    "    def send(self,command:str, content):\n",
    "        self.outQueue.put({'command':command,'content':content})\n",
    "\n",
    "    def message_sender_loop(self):\n",
    "        while True:\n",
    "            message = self.outQueue.get(None)\n",
    "            asyncio.run(self.ws.send(json.dumps(message, indent=4)))\n",
    "\n",
    "# start the server in a separate thread to avoid blocking\n",
    "import threading\n",
    "server = Server()\n",
    "t=threading.Thread(target=server.start)\n",
    "t.start()\n",
    "\n",
    "# the interface to the server\n",
    "class WSManager:\n",
    "    def __init__(self,server:Server):\n",
    "        self.debug = False\n",
    "        self.server = server\n",
    "\n",
    "#server.send(\"action\",{\"voltage\":[1,0,0,0,100,200,100,100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def flatten(list_of_lists):\n",
    "    if len(list_of_lists) == 0:\n",
    "        return list(list_of_lists)\n",
    "    if hasattr(list_of_lists[0], '__iter__'):\n",
    "        return flatten(list_of_lists[0]) + flatten(list_of_lists[1:])\n",
    "    return list(list_of_lists[:1]) + flatten(list_of_lists[1:])\n",
    "def decomposeCosSin(angle):\n",
    "    return [np.cos(angle), np.sin(angle)]\n",
    "def processFeature(state:dict,targetPos):\n",
    "    feature = []\n",
    "    feature.append(state['baseLinkPos']['x']-targetPos[0])\n",
    "    feature.append(state['baseLinkPos']['y']-targetPos[1])\n",
    "    feature.append(decomposeCosSin(state['baseLinkOrientation']))\n",
    "    feature.append(state['baseLinkVelocity']['x'])\n",
    "    feature.append(state['baseLinkVelocity']['y'])\n",
    "    feature.append(state['baseLinkAngularVelocity'])\n",
    "    feature.append(decomposeCosSin(state['wheelBaseOrientation']))\n",
    "    feature.append(state['wheelSpeed'])\n",
    "    feature = flatten(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Q(nn.Module):\n",
    "    def __init__(self,state_size,action_size,hidden_size):\n",
    "        super(Q, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.fc = nn.Sequential(\n",
    "        nn.Linear(state_size+action_size,hidden_size),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(hidden_size,hidden_size),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(hidden_size,1)\n",
    "        )\n",
    "\n",
    "    def forward(self,state,action):\n",
    "        return self.fc(torch.cat([state,action],dim=1))\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self,state_size,action_size,hidden_size):\n",
    "        super(Policy, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.fc = nn.Sequential(\n",
    "        nn.Linear(state_size,hidden_size),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(hidden_size,hidden_size),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(hidden_size,action_size)\n",
    "        )\n",
    "\n",
    "    def forward(self,state):\n",
    "        return self.fc(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q = Q(state_size=19,action_size=8,hidden_size=64)\n",
    "policy = Policy(state_size=19,action_size=8,hidden_size=64)\n",
    "targetPos = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 start\n",
      "step 1 start\n",
      "step 2 start\n",
      "step 3 start\n",
      "step 4 start\n",
      "step 5 start\n",
      "step 6 start\n",
      "step 7 start\n",
      "step 8 start\n",
      "step 9 start\n",
      "step 10 start\n",
      "step 11 start\n",
      "step 12 start\n",
      "step 13 start\n",
      "step 14 start\n",
      "step 15 start\n",
      "step 16 start\n",
      "step 17 start\n",
      "step 18 start\n",
      "step 19 start\n",
      "step 20 start\n",
      "step 21 start\n",
      "step 22 start\n",
      "step 23 start\n",
      "step 24 start\n",
      "step 25 start\n",
      "step 26 start\n",
      "step 27 start\n",
      "step 28 start\n",
      "step 29 start\n",
      "step 30 start\n",
      "step 31 start\n",
      "step 32 start\n",
      "step 33 start\n",
      "step 34 start\n",
      "step 35 start\n",
      "step 36 start\n",
      "step 37 start\n",
      "step 38 start\n",
      "step 39 start\n",
      "step 40 start\n",
      "step 41 start\n",
      "step 42 start\n",
      "step 43 start\n",
      "step 44 start\n",
      "step 45 start\n",
      "step 46 start\n",
      "step 47 start\n",
      "step 48 start\n",
      "step 49 start\n",
      "step 50 start\n",
      "step 51 start\n",
      "step 52 start\n",
      "step 53 start\n",
      "step 54 start\n",
      "step 55 start\n",
      "step 56 start\n",
      "step 57 start\n",
      "step 58 start\n",
      "step 59 start\n",
      "step 60 start\n",
      "step 61 start\n",
      "step 62 start\n",
      "step 63 start\n",
      "step 64 start\n",
      "step 65 start\n",
      "step 66 start\n",
      "step 67 start\n",
      "step 68 start\n",
      "step 69 start\n",
      "step 70 start\n",
      "step 71 start\n",
      "step 72 start\n",
      "step 73 start\n",
      "step 74 start\n",
      "step 75 start\n",
      "step 76 start\n",
      "step 77 start\n",
      "step 78 start\n",
      "step 79 start\n",
      "step 80 start\n",
      "step 81 start\n",
      "step 82 start\n",
      "step 83 start\n",
      "step 84 start\n",
      "step 85 start\n",
      "step 86 start\n",
      "step 87 start\n",
      "step 88 start\n",
      "step 89 start\n",
      "step 90 start\n",
      "step 91 start\n",
      "step 92 start\n",
      "step 93 start\n",
      "step 94 start\n",
      "step 95 start\n",
      "step 96 start\n",
      "step 97 start\n",
      "step 98 start\n",
      "step 99 start\n"
     ]
    }
   ],
   "source": [
    "server.debug = False\n",
    "for t in range(100):\n",
    "    state = processFeature(server.inQueue.get()['content'],targetPos)\n",
    "    print(f'step {t} start')\n",
    "    action = policy(torch.tensor(state,dtype=torch.float))*5000\n",
    "    server.send(\"action\",{\"voltage\":list(action.detach().numpy().tolist())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WaitableQueue at 0x1c7f7aadf10 maxsize=0 _queue=[{'command': 'state', 'content': {'baseLinkPos': {'x': -0.155428052, 'y': -0.04696183}, 'baseLinkOrientation': 6.28281832, 'baseLinkVelocity': {'x': 0.0172630455, 'y': -0.00125027169}, 'baseLinkAngularVelocity': -0.000331740855, 'wheelBaseOrientation': [3.00465751, 3.28057742, 3.01581454, 3.11644673], 'wheelSpeed': [-0.03694538, -0.0458802022, -0.03772101, -0.04005027]}}] tasks=2>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.inQueue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server.send(\"action\",{\"voltage\":[10,10,10,10,-100,-200,-100,-100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  458.5170,  -498.8667,  1170.6143,  1094.3835, -1245.0892, -1157.3398,\n",
       "          691.8254,  -910.0997], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy(torch.tensor(state,dtype=torch.float))*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9624776d510bbc019f6ff189fc1336bb72bf6a7e32ae91ed9f1b177f47b3d26"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
